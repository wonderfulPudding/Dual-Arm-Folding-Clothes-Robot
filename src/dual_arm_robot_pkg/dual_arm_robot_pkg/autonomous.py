#!/usr/bin/env python3
"""
ììœ¨ ì‹¤í–‰ (ì†ìˆ˜ê±´ ê°ì§€ í¬í•¨)
"""

import torch
import torch.nn as nn
import numpy as np
import time
import glob
from pathlib import Path
from dynamixel_sdk import *
import cv2

print("=== ììœ¨ ì‹¤í–‰ (ì†ìˆ˜ê±´ ê°ì§€) ===\n")

CHECKPOINT_PATH = Path("~/handkerchief_checkpoints/best_model.pth").expanduser()
PROTOCOL_VERSION = 1.0
BAUDRATE = 1000000

FOLLOWER1_IDS = list(range(1, 7))
FOLLOWER2_IDS = list(range(11, 17))

ADDR_TORQUE_ENABLE = 24
ADDR_GOAL_POSITION = 30
ADDR_PRESENT_POSITION = 36
ADDR_MOVING_SPEED = 32

MOTOR_SPEED = 200
CAMERA_INDEX = 4

# ì†ìˆ˜ê±´ ìƒ‰ìƒ ë²”ìœ„ (HSV) - í°ìƒ‰ ì†ìˆ˜ê±´ ê¸°ì¤€
# ë‹¤ë¥¸ ìƒ‰ìƒì´ë©´ ì¡°ì • í•„ìš”
HANDKERCHIEF_COLOR_LOWER = np.array([0, 0, 180])    # í°ìƒ‰ í•˜í•œ
HANDKERCHIEF_COLOR_UPPER = np.array([180, 30, 255])  # í°ìƒ‰ ìƒí•œ


def detect_ports():
    usb_ports = sorted(glob.glob("/dev/ttyUSB*"))
    config = {}
    if len(usb_ports) >= 2:
        config['follower1'] = usb_ports[0]
        config['follower2'] = usb_ports[1]
    return config


def detect_handkerchief(frame):
    """
    ì†ìˆ˜ê±´ ê°ì§€ (ìƒ‰ìƒ ê¸°ë°˜)
    
    Returns:
        detected (bool): ì†ìˆ˜ê±´ ê°ì§€ ì—¬ë¶€
        bbox (tuple): (x, y, w, h) ë°”ìš´ë”© ë°•ìŠ¤
        area (int): ê°ì§€ëœ ì˜ì—­ í¬ê¸°
    """
    # HSV ë³€í™˜
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    # ìƒ‰ìƒ ë§ˆìŠ¤í¬
    mask = cv2.inRange(hsv, HANDKERCHIEF_COLOR_LOWER, HANDKERCHIEF_COLOR_UPPER)
    
    # ë…¸ì´ì¦ˆ ì œê±°
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    # ì»¨íˆ¬ì–´ ì°¾ê¸°
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        return False, None, 0
    
    # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì°¾ê¸°
    largest_contour = max(contours, key=cv2.contourArea)
    area = cv2.contourArea(largest_contour)
    
    # ìµœì†Œ í¬ê¸° í•„í„° (ë„ˆë¬´ ì‘ì€ ê±´ ë¬´ì‹œ)
    MIN_AREA = 5000
    if area < MIN_AREA:
        return False, None, 0
    
    # ë°”ìš´ë”© ë°•ìŠ¤
    x, y, w, h = cv2.boundingRect(largest_contour)
    
    return True, (x, y, w, h), area


class ImprovedPolicy(nn.Module):
    def __init__(self, state_dim=24, action_dim=12, hidden_dim=256):
        super().__init__()
        
        self.encoder = nn.Sequential(
            nn.Linear(state_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
        )
        
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, action_dim),
        )
    
    def forward(self, state):
        encoded = self.encoder(state)
        action = self.decoder(encoded)
        return action


class AutonomousController:
    def __init__(self):
        self.ports = detect_ports()
        print(f"í¬íŠ¸ ì„¤ì •:")
        print(f"  íŒ”ë¡œì›Œ1 (ID 1~6): {self.ports['follower1']}")
        print(f"  íŒ”ë¡œì›Œ2 (ID 11~16): {self.ports['follower2']}\n")
        
        self.ph_follower1 = None
        self.ph_follower2 = None
        self.pkt_handler = None
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ë””ë°”ì´ìŠ¤: {self.device}\n")
        
        self.model = ImprovedPolicy(hidden_dim=256).to(self.device)
        
        if CHECKPOINT_PATH.exists():
            checkpoint = torch.load(CHECKPOINT_PATH, map_location=self.device)
            
            if 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
                loss = checkpoint.get('loss', 'N/A')
                epoch = checkpoint.get('epoch', 'N/A')
                print(f"âœ“ ëª¨ë¸ ë¡œë“œ: epoch {epoch}, loss {loss:.4f}\n")
            else:
                self.model.load_state_dict(checkpoint)
                print(f"âœ“ ëª¨ë¸ ë¡œë“œ: {CHECKPOINT_PATH}\n")
            
            self.model.eval()
        else:
            print(f"âœ— ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ: {CHECKPOINT_PATH}\n")
            exit(1)
        
        self.prev_qpos = None
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.camera = cv2.VideoCapture(CAMERA_INDEX)
        if not self.camera.isOpened():
            print(f"âœ— ì¹´ë©”ë¼ {CAMERA_INDEX}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            self.camera = None
        else:
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
            print(f"âœ“ ì¹´ë©”ë¼: /dev/video{CAMERA_INDEX}\n")
            
            # í”„ë¦¬ë·° ìœˆë„ìš°
            cv2.namedWindow('Handkerchief Detection', cv2.WINDOW_NORMAL)
            cv2.resizeWindow('Handkerchief Detection', 960, 540)
    
    def connect_robot(self):
        print("[ë¡œë´‡ ì—°ê²°]")
        self.pkt_handler = PacketHandler(PROTOCOL_VERSION)
        
        self.ph_follower1 = PortHandler(self.ports['follower1'])
        if not self.ph_follower1.openPort():
            raise Exception(f"íŒ”ë¡œì›Œ1 ì—°ê²° ì‹¤íŒ¨: {self.ports['follower1']}")
        self.ph_follower1.setBaudRate(BAUDRATE)
        print(f"  âœ“ íŒ”ë¡œì›Œ1: {self.ports['follower1']} (ID 1~6)")
        
        self.ph_follower2 = PortHandler(self.ports['follower2'])
        if not self.ph_follower2.openPort():
            raise Exception(f"íŒ”ë¡œì›Œ2 ì—°ê²° ì‹¤íŒ¨: {self.ports['follower2']}")
        self.ph_follower2.setBaudRate(BAUDRATE)
        print(f"  âœ“ íŒ”ë¡œì›Œ2: {self.ports['follower2']} (ID 11~16)")
        
        print("\n[ëª¨í„° í† í¬ ì„¤ì •]")
        
        success1 = 0
        for mid in FOLLOWER1_IDS:
            result, error = self.pkt_handler.write1ByteTxRx(self.ph_follower1, mid, ADDR_TORQUE_ENABLE, 1)
            
            if result == COMM_SUCCESS and error == 0:
                self.pkt_handler.write2ByteTxRx(self.ph_follower1, mid, ADDR_MOVING_SPEED, MOTOR_SPEED)
                
                torque, _, _ = self.pkt_handler.read1ByteTxRx(self.ph_follower1, mid, ADDR_TORQUE_ENABLE)
                if torque == 1:
                    success1 += 1
        
        print(f"  â†’ íŒ”ë¡œì›Œ1: {success1}/{len(FOLLOWER1_IDS)} ì„±ê³µ")
        
        success2 = 0
        for mid in FOLLOWER2_IDS:
            result, error = self.pkt_handler.write1ByteTxRx(self.ph_follower2, mid, ADDR_TORQUE_ENABLE, 1)
            
            if result == COMM_SUCCESS and error == 0:
                self.pkt_handler.write2ByteTxRx(self.ph_follower2, mid, ADDR_MOVING_SPEED, MOTOR_SPEED)
                
                torque, _, _ = self.pkt_handler.read1ByteTxRx(self.ph_follower2, mid, ADDR_TORQUE_ENABLE)
                if torque == 1:
                    success2 += 1
        
        print(f"  â†’ íŒ”ë¡œì›Œ2: {success2}/{len(FOLLOWER2_IDS)} ì„±ê³µ\n")
        
        if success1 == 0 and success2 == 0:
            raise Exception("ëª¨ë“  ëª¨í„° í† í¬ í™œì„±í™” ì‹¤íŒ¨!")
    
    def disconnect_robot(self):
        try:
            for ph in [self.ph_follower1, self.ph_follower2]:
                if ph:
                    ph.closePort()
        except:
            pass
        
        if self.camera:
            self.camera.release()
        
        cv2.destroyAllWindows()
    
    def get_current_state(self):
        f1_pos = []
        for mid in FOLLOWER1_IDS:
            pos, _, _ = self.pkt_handler.read2ByteTxRx(self.ph_follower1, mid, ADDR_PRESENT_POSITION)
            f1_pos.append(pos if pos else 512)
        
        f2_pos = []
        for mid in FOLLOWER2_IDS:
            pos, _, _ = self.pkt_handler.read2ByteTxRx(self.ph_follower2, mid, ADDR_PRESENT_POSITION)
            f2_pos.append(pos if pos else 512)
        
        qpos = np.array(f1_pos + f2_pos, dtype=np.float32)
        
        if self.prev_qpos is None:
            qvel = np.zeros(12, dtype=np.float32)
        else:
            qvel = qpos - self.prev_qpos
        
        self.prev_qpos = qpos.copy()
        
        state = np.concatenate([qpos, qvel])
        
        return state, qpos
    
    def execute_action(self, action):
        action = action.cpu().numpy()
        
        for i, mid in enumerate(FOLLOWER1_IDS):
            pos = int(np.clip(action[i], 0, 1023))
            self.pkt_handler.write2ByteTxRx(self.ph_follower1, mid, ADDR_GOAL_POSITION, pos)
        
        for i, mid in enumerate(FOLLOWER2_IDS):
            pos = int(np.clip(action[i+6], 0, 1023))
            self.pkt_handler.write2ByteTxRx(self.ph_follower2, mid, ADDR_GOAL_POSITION, pos)
    
    def run(self, duration=30.0):
        print("[ììœ¨ ì‹¤í–‰ ì‹œì‘]")
        print(f"  ì‹œê°„: {duration}ì´ˆ")
        print("  Ctrl+Cë¡œ ì¤‘ë‹¨\n")
        
        start_time = time.time()
        step = 0
        handkerchief_detected = False
        
        try:
            while (time.time() - start_time) < duration:
                # ìƒíƒœ ì½ê¸°
                state, current_qpos = self.get_current_state()
                
                # í–‰ë™ ì˜ˆì¸¡
                with torch.no_grad():
                    state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                    action_tensor = self.model(state_tensor).squeeze(0)
                
                # í–‰ë™ ì‹¤í–‰
                self.execute_action(action_tensor)
                
                # ì¹´ë©”ë¼ë¡œ ì†ìˆ˜ê±´ ê°ì§€
                if self.camera:
                    ret, frame = self.camera.read()
                    
                    if ret:
                        detected, bbox, area = detect_handkerchief(frame)
                        
                        # í”„ë ˆì„ì— í‘œì‹œ
                        display_frame = frame.copy()
                        
                        if detected:
                            if not handkerchief_detected:
                                print(f"\n  ğŸŸ¢ ì†ìˆ˜ê±´ ê°ì§€ë¨! (ë©´ì : {area})")
                                handkerchief_detected = True
                            
                            x, y, w, h = bbox
                            
                            # ì´ˆë¡ìƒ‰ ë°•ìŠ¤
                            cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 3)
                            
                            # í…ìŠ¤íŠ¸
                            cv2.putText(display_frame, "HANDKERCHIEF DETECTED", (x, y-10),
                                      cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                            cv2.putText(display_frame, f"Area: {area}", (x, y+h+30),
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                        else:
                            if handkerchief_detected:
                                print(f"\n  ğŸ”´ ì†ìˆ˜ê±´ ê°ì§€ í•´ì œ")
                                handkerchief_detected = False
                            
                            # ë¹¨ê°„ìƒ‰ í…ìŠ¤íŠ¸
                            cv2.putText(display_frame, "Searching...", (20, 50),
                                      cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                        
                        # ìŠ¤í… ì •ë³´
                        cv2.putText(display_frame, f"Step: {step}", (20, display_frame.shape[0] - 50),
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                        
                        elapsed = time.time() - start_time
                        cv2.putText(display_frame, f"Time: {elapsed:.1f}s", (20, display_frame.shape[0] - 20),
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                        
                        cv2.imshow('Handkerchief Detection', display_frame)
                        
                        # í‚¤ ì…ë ¥
                        key = cv2.waitKey(1) & 0xFF
                        if key == ord('q') or key == 27:
                            print("\nâœ— ì‚¬ìš©ì ì¤‘ë‹¨")
                            break
                
                step += 1
                
                if step % 30 == 0:
                    elapsed = time.time() - start_time
                    status = "ğŸŸ¢ ê°ì§€ë¨" if handkerchief_detected else "ğŸ”´ ë¯¸ê°ì§€"
                    print(f"  â–Œ {step}ìŠ¤í… ({elapsed:.1f}ì´ˆ) - {status}")
                
                time.sleep(0.03)
        
        except KeyboardInterrupt:
            print("\nâœ— ì¤‘ë‹¨ë¨")
        
        print(f"\nâœ“ ììœ¨ ì‹¤í–‰ ì™„ë£Œ ({step}ìŠ¤í…)\n")


def main():
    print("="*60)
    print("ììœ¨ ì‹¤í–‰ ëª¨ë“œ (ì†ìˆ˜ê±´ ê°ì§€)")
    print("="*60 + "\n")
    
    controller = AutonomousController()
    
    try:
        controller.connect_robot()
        
        input("\nì¤€ë¹„ë˜ë©´ Enterë¥¼ ëˆŒëŸ¬ ì‹œì‘...")
        
        controller.run(duration=30.0)
        
        print("="*60)
        print("âœ“ ì™„ë£Œ!")
        print("="*60)
    
    except Exception as e:
        print(f"\nâœ— ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        controller.disconnect_robot()


if __name__ == "__main__":
    main()
